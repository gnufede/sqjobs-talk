#+TITLE: SQJobs
#+AUTHOR: Federico Mon
#+EMAIL: federico.mon@ticketea.com
#+DATE: 2015-11-21
#+OPTIONS: num:nil toc:nil todo:nil
# #+REVEAL_ROOT: ./reveal.js/
#+REVEAL_ROOT: https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.2.0/
#+REVEAL_EXTRA_CSS: ./custom.css
#+REVEAL_SLIDE_NUMBER: nil
#+REVEAL_THEME: league
#+REVEAL_BACKGROUND: #272822


* Intro
** Intro to Async Queued Task Execution
#+NAME:   fig:intro
[[./img/intro.png]]
#+BEGIN_NOTES
  * A la izquierda, los componentes de software que encolan trabajos.
  * En el centro, otro componente se encarga de mantener dos colas de mensajes.
  * A la derecha, los workers leen de las colas de mensajes, y ejecutan los trabajos.
#+END_NOTES

** SQJobs implementation
#+NAME:   fig:sqjobs
[[./img/sqjobs1.png]]
#+BEGIN_NOTES
  * En SQJobs, los mensajes se pueden encolar con python, o con otros lenguajes usando
    el api de SQS.
  * Las colas se almacenan en SQS.
  * Los workers están hechos usando Django.
#+END_NOTES

# ** Sqjobs is a simple queue jobs system.
# ** Jobs are run asynchronously "in background"
# ** Jobs can be run even in other machines
# ** Because a Queue of jobs is used
# ** Several ends can create a Job
# ** Worker is the end where the job is consumed
# ** The worker is implemented in Python.
# ** The broker can be Python or other.
# ** At the moment, the broker is SQS.
# ** Cheatsheet

* History
** Not so long ago, Celery was used in Ticketea.
#+NAME:   fig:celery
[[./img/celery.gif]]
#+BEGIN_NOTES
  * Usabamos modelo activo-activo.
  * Dos servidores funcionan como uno, pero más tolerante a fallos.
  * Posiblemente no usábamos la configuración idónea de Celery en nuestro caso.
#+END_NOTES
** Some Split-brains happened in RabbitMQ, leading to a lot of work to fix the situation.
# #+NAME:   fig:splitbrain
# [[./img/splitbrain.gif]]
#+NAME:   fig:brain
[[./img/brain.gif]]
#+BEGIN_NOTES
  * Split brain, cuando los dos servidores pierden la comunicación
    y tienen información diferente
  * Al entrar a depurar Celery, hay reimplementación de módulos
    como "exec"
#+END_NOTES
** Workers go on strike
#+NAME:   fig:issue
[[./img/maraujop1.png]]
#+BEGIN_NOTES
  * Bug report de Miguel
  * Vemos como los workers dejan de ejecutar tareas.
  * En la gráfica no se ve, pero llega un flujo
    constante de trabajos.
#+END_NOTES
** 
#+NAME:   fig:issue2
[[./img/maraujop2.png]]
#+BEGIN_NOTES
  * Registramos errores de Timeouts de celery
  * Al intentar depurar encontramos reimplementación de
    módulos como process, etc. Complicando mucho el trabajo.
#+END_NOTES

** Migrations to OpenERP were taking >48 hours
#+NAME:   fig:sleepy
[[./img/sleepy.gif]]
#+BEGIN_NOTES
  * Y no terminaba bien.
#+END_NOTES


** The goal was to quit using Celery and RabbitMQ and use something simpler instead
#+NAME:   fig:rainbow
[[./img/rainbow.gif]]
#+BEGIN_NOTES
  * Había que cambiar la situación.
  * No parecía que la cosa pudiera ir mucho peor.
#+END_NOTES


** For more details you can ask Iñaki or Miguel
~@igalarzab~ and ~@maraujop~

* The problem
** Resilience in a network
"Resiliency is the ability to provide and maintain an acceptable
level of service in the face of faults and challenges to normal operation."
#+NAME:   fig:outage
[[./img/outage.gif]]
#+BEGIN_NOTES
  * Resistencia en la red.
  * Como se comporta el sistema en situacion de estres
#+END_NOTES


** Possible solutions:
*** Use an existing solution
 RQ (Redis)
#+NAME:   fig:confused
[[./img/confused.gif]]
#+BEGIN_NOTES
  * Celery no es la única opción
  * Ninguna razón real para no haber probado RQ
  * Posibilidad de que ocurriese lo mismo, perder mensajes.
#+END_NOTES

*** Create our own solution
#+NAME:   fig:ourselves
[[./img/ourselves.gif]]
#+ATTR_REVEAL: :frag appear
  * Easier to debug
  * Choose the broker we want
  * Scratch your own itch
#+BEGIN_NOTES
  * Queríamos probar SQS
  * Ningún problema para depurar
  * Aprender en el camino
#+END_NOTES

* Crafting the solution
** Different delivery guarantees
#+ATTR_REVEAL: :frag appear
 * Only-once-delivery
 * At-least-once-delivery
#+BEGIN_NOTES
  * Los brokers de mensajes ofrecen garantias de entrega.
  * Exactamente una entrega, o al menos una entrega
#+END_NOTES

** If we pick only-once-delivery...
*** What if messages are dropped?
# #+NAME:   fig:FAIL
# [[./img/fail.gif]]
#+NAME:   fig:messages_dropped
[[./img/messages_dropped.gif]]
#+BEGIN_NOTES
  * Si sólo nos lo entregan una vez y se pierde, adios
#+END_NOTES

** If we pick at-least-once-delivery...
*** Then, what if messages are received more than once?
#+NAME:   fig:double_fail
[[./img/double_fail.gif]]
#+BEGIN_NOTES
  * Si aplicamos varias veces la misma operación,
    el resultado puede ser diferente de lo planeado
#+END_NOTES

*** Write Idempotent Jobs
#+NAME:   fig:Idempotence
[[./img/idem.gif]]
#+BEGIN_NOTES
  * Escribiendo los trabajos de tal forma, que no
    afecte aplicarlos 1 vez o N veces.
  * Básicamente, si el estado está en el mensaje.
#+END_NOTES

* The success
** Migration to OpenERP took 6 hours
#+NAME:   fig:yes
[[./img/yes.gif]]
#+BEGIN_NOTES
  * Y esta vez, sí terminó correctamente.
#+END_NOTES

** SQjobs workers are quite fast, and easier to debug than Celery's
At least for us :)
#+NAME:   fig:MELOCOTONAZO
[[./img/melocotonazo.gif]]
#+BEGIN_NOTES
  * La infraestructura es muy simple,
    añade muy poco overhead.
#+END_NOTES


* The Job
** Must be in ~jobs.py~
** ~models.py~ must exist
** Sample Job
#+BEGIN_SRC python
from sqjobs.job import Job

class AdderJob(Job):
    name = 'adder_job'
    queue = 'my_queue'
 
    def run(self, *args, **kwargs):
        return sum(args)
#+END_SRC

* Launching a Job
** From python
#+BEGIN_SRC python
from sqjobs import create_sqs_broker
from myapp.jobs import AdderJob

kwargs = {
    'access_key': settings.SQJOBS_SQS_ACCESS_KEY,
    'secret_key': settings.SQJOBS_SQS_ACCESS_KEY
}
broker = create_sqs_broker(**kwargs)
broker.add_job(AdderJob, *[1, 2, 3, 4])
#+END_SRC

** From PHP
#+BEGIN_SRC php
$payload = array(
    'name' => $task_name,
    'args' => $args,
    'kwargs' => $kwargs
);
$json_payload = json_encode($payload);

$this->_sqs = new AmazonSQS($amazon_config['aws_key'], $amazon_config['aws_secret_key']);
$result = $this->_sqs->send_message($this->_queue_urls[$queue_name], base64_encode($json_payload));
#+END_SRC

* The Worker
** Workers listen in a queue and execute jobs
** Built as a django command
** You can launch as many as you want
** Usage:
#+BEGIN_SRC bash
$ ./manage.py sqjobs worker $queue_name
#+END_SRC

* Eager mode
** Eager mode is a simpler execution mode
** Tasks are run synchronously
** Instead of sending them to the message broker
** So there is no need for a queue nor running workers.
** Meant for development and unit testing.
** Sample execution
#+BEGIN_SRC python
>>> from sqjobs import create_eager_broker
>>> broker = create_eager_broker()
>>> from jobs import AdderJob
>>> job_added = broker.add_job(AdderJob, *[1, 2, 3])
>>> job_added 
('fdb005d3-276f-4f75-8e8e-c8fcde67043c', AdderJob())
>>> job_added[1].result
6
#+END_SRC

* A Result-backed Job
** Status of the job is stored in a database.
** It uses a Django model, Django is needed here.
** Can be used, for example, in a web application, to know when the job is done or fails, and act accordingly.
** Sample ResultJob
#+BEGIN_SRC python
from sqjobs.contrib.django.djsqjobs.result_job import ResultJob

class DummyResultJob(ResultJob):
    name = 'dummy_result_job'
    queue = 'dummy_queue'
 
    def run(self, *args, **kwargs):
        pass
#+END_SRC

** How to use a resultjob
#+BEGIN_SRC python
>>> from sqjobs.contrib.django.djsqjobs.models import JobStatus
>>> my_job = JobStatus.objects.get(job_id='1234')
>>> if my_job.status == JobStatus.SUCCESS:
...     print my_job.result
#+END_SRC

* A Periodic task
** Will be executed like if they were in a crontab.
** This requires another piece of software
called ~Beater~
** Cron ranges can be localized to a timezone
** And support daylight saving changes.
** Sample PeriodicJob
#+BEGIN_SRC python
from djsqjobs import PeriodicJob

class DummyPeriodicJob(PeriodicJob):
    name = "dummy_periodic_job"
    queue = "my_queue"

    schedule = "1 0 * * *"
    timezone = "Europe/Madrid"

    def run(self, *args, **kwargs):
        pass
#+END_SRC

* The Beater
** A special component that queue jobs at the right moment.
** By waking up every certain time, check what jobs should be queued, and reprogram them.
** You can launch as many as you need.
** So if any of them dies, the others will queue your job.
** They use the django database to synchronise and launch the job only once.
** Despite your jobs should be idempotent.
** Usage:
#+BEGIN_SRC bash
$ ./manage.py sqjobs beater $queue_name
#+END_SRC

* Set up and Tear down
** Job execution is divided in three different stages:
~set_up~, ~run~, ~tear_down~
#+ATTR_REVEAL: :frag appear
 * Only ~run~ is mandatory
 * ~set_up~ would be called before run if exists
 * And ~tear_down~ right after ~run~ if exists.

** Sample Job
#+BEGIN_SRC python
from abc import abstractmethod, ABCMeta
from six import add_metaclass
import logging

logger = logging.getLogger('timed_job')

@add_metaclass(ABCMeta)
class TimedJob(Job):

    def set_up(self, *args, **kwargs):
        super(TimedJob, self).set_up(*args, **kwargs)
        self.start_time = datetime.now()

    def tear_down(self, *args, **kwargs):
        end_time = datetime.now()
        delta = end_time - self.start_time
        logger.info('%s finished in %d seconds' % (self.name, (delta * 1000).seconds))
        super(TimedJob, self).tear_down(*args, **kwargs)

    @abstractmethod
    def run(self, *args, **kwargs):
        raise NotImplementedError
#+END_SRC

* Failure and Success
** We can define failure and success methods
 ~on_success~ and ~on_failure~ methods will be called
depending on the output of our job execution.

** Example of ~on_success~ and ~on_failure~
#+BEGIN_SRC python
from abc import abstractmethod, ABCMeta
from six import add_metaclass
import logging

logger = logging.getLogger('logger_job')

@add_metaclass(ABCMeta)
class LoggerJob(Job):

    def on_success(self, *args, **kwargs):
        logger.log('Successfully finished job %s' % self.name)
        super(LoggerJob, self).on_success(*args, **kwargs)

    def on_failure(self, *args, **kwargs):
        logger.log('Failed job %s' % self.name)
        super(LoggerJob, self).on_failure(*args, **kwargs)

    @abstractmethod
    def run(self, *args, **kwargs):
        raise NotImplementedError
#+END_SRC

* Thanks
 ~@gnufede~
